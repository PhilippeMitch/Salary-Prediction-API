{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ada487d-223b-4f0c-872e-2c71b135f14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessay libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score,\n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    classification_report, \n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd32465-2f30-4ae0-8ce7-79fc9ccd96f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass   fnlgt  education      marital-status  \\\n",
       "0   39         State-gov   77516  Bachelors       Never-married   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors  Married-civ-spouse   \n",
       "2   38           Private  215646    HS-grad            Divorced   \n",
       "\n",
       "          occupation   relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0       Adm-clerical  Not-in-family  White  Male          2174             0   \n",
       "1    Exec-managerial        Husband  White  Male             0             0   \n",
       "2  Handlers-cleaners  Not-in-family  White  Male             0             0   \n",
       "\n",
       "   hours-per-week native-country salary  \n",
       "0              40  United-States  <=50K  \n",
       "1              13  United-States  <=50K  \n",
       "2              40  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "df = pd.read_csv('data/clean_census.csv')\n",
    "# Display the three first rows from the dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bd0b4a-9806-4e4a-b194-c3e5878aaf98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(\n",
    "    X, categorical_features=[], label=None, training=True, encoder=None, lb=None\n",
    "):\n",
    "    \"\"\" Process the data used in the machine learning pipeline.\n",
    "\n",
    "    Processes the data using one hot encoding for the categorical features and a\n",
    "    label binarizer for the labels. This can be used in either training or\n",
    "    inference/validation.\n",
    "\n",
    "    Note: depending on the type of model used, you may want to add in functionality that\n",
    "    scales the continuous data.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X : pd.DataFrame\n",
    "        Dataframe containing the features and label. Columns in `categorical_features`\n",
    "    categorical_features: list[str]\n",
    "        List containing the names of the categorical features (default=[])\n",
    "    label : str\n",
    "        Name of the label column in `X`. If None, then an empty array will be returned\n",
    "        for y (default=None)\n",
    "    training : bool\n",
    "        Indicator if training mode or inference/validation mode.\n",
    "    encoder : sklearn.preprocessing._encoders.OneHotEncoder\n",
    "        Trained sklearn OneHotEncoder, only used if training=False.\n",
    "    lb : sklearn.preprocessing._label.LabelBinarizer\n",
    "        Trained sklearn LabelBinarizer, only used if training=False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Processed data.\n",
    "    y : np.array\n",
    "        Processed labels if labeled=True, otherwise empty np.array.\n",
    "    encoder : sklearn.preprocessing._encoders.OneHotEncoder\n",
    "        Trained OneHotEncoder if training is True, otherwise returns the encoder passed\n",
    "        in.\n",
    "    lb : sklearn.preprocessing._label.LabelBinarizer\n",
    "        Trained LabelBinarizer if training is True, otherwise returns the binarizer\n",
    "        passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    if label is not None:\n",
    "        y = X[label]\n",
    "        X = X.drop([label], axis=1)\n",
    "    else:\n",
    "        y = np.array([])\n",
    "\n",
    "    X_categorical = X[categorical_features].values\n",
    "    X_continuous = X.drop(*[categorical_features], axis=1)\n",
    "\n",
    "    if training is True:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        lb = LabelBinarizer()\n",
    "        X_categorical = encoder.fit_transform(X_categorical)\n",
    "        y = lb.fit_transform(y.values).ravel()\n",
    "    else:\n",
    "        X_categorical = encoder.transform(X_categorical)\n",
    "        try:\n",
    "            y = lb.fit_transform(y.values).ravel()\n",
    "        # Catch the case where y is None because we're doing inference.\n",
    "        except AttributeError as error:\n",
    "            print(\"Error occur: \", error)\n",
    "\n",
    "    X = np.concatenate([X_continuous, X_categorical], axis=1)\n",
    "    return X, y, encoder, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f7cd9a-e51d-4b9d-9244-12de9f5235ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the categorical feature except the column salary\n",
    "categorical_features = list(df.select_dtypes(['object', 'category']).columns)[:-1]\n",
    "# Show the columns\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f74d6e-2621-4666-98fc-f6e1f354ed08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and test\n",
    "train, test = train_test_split(df, shuffle=True, stratify=None, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe76b1c8-f35a-4c0f-809d-e838b888f136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder and LabelBinarizer() objects\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "binarizer = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be644ac7-ba9c-4f74-baef-5e698e4a86c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the metrics from the trained model\n",
    "def compute_model_metrics(y, preds):\n",
    "    \"\"\"\n",
    "    Validates the trained machine learning model using precision, recall, and F1.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    y : np.array\n",
    "        Known labels, binarized.\n",
    "    preds : np.array\n",
    "        Predicted labels, binarized.\n",
    "    Returns\n",
    "    -------\n",
    "    precision : float\n",
    "    recall : float\n",
    "    fbeta : float\n",
    "    \"\"\"\n",
    "    fbeta = fbeta_score(y, preds, beta=1, zero_division=1)\n",
    "    precision = precision_score(y, preds, zero_division=1)\n",
    "    recall = recall_score(y, preds, zero_division=1)\n",
    "    return precision, recall, fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fae87f9-8ebd-437a-a9e0-8f06fc93333e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional: implement hyperparameter tuning.\n",
    "def train_model(X_train, y_train, models):\n",
    "    \"\"\"\n",
    "    Trains a machine learning model and returns it.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X_train : np.array\n",
    "        Training data.\n",
    "    y_train : np.array\n",
    "        Labels.\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        Trained machine learning model.\n",
    "    \"\"\"\n",
    "\n",
    "    for key in models.keys():\n",
    "\n",
    "        models[key].fit(X_train, y_train)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b9df36-038d-4618-a290-7defc516835f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the processed train data\n",
    "X_train, y_train, encoder, lb = process_data(\n",
    "                        train, categorical_features=categorical_features, label=\"salary\", training=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "70b8eabb-0c8b-47ab-ba22-a22aa567213b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary for differents models\n",
    "models = {}\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "models['Extrat Classfier'] = ExtraTreesClassifier(n_estimators=50)\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "models['Gradient Boosting'] = GradientBoostingClassifier(n_estimators=333, learning_rate=0.8, max_depth=5, random_state=0)\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "models['XGB Classifier'] = XGBClassifier(objective='binary:logistic', eta=0.3, max_depth= 5, eval_metric = 'aucpr')\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062bebe-6196-4c6d-9bd3-dc79d03738cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_models = train_model(X_train, y_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1c083b-bd7a-40e3-b925-ae4c816f3676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the result metrics into a dataframe\n",
    "def df_model_results(trained_models, X_data, y_data):\n",
    "    \"\"\"\n",
    "    Get model result into a dataframe\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    trained_models : dict\n",
    "                A dictionary of the trained models\n",
    "    X_data : numpy.ndarray\n",
    "        The data we want to evaluate the model on\n",
    "    y_data : numpy.ndarray\n",
    "        The actual label of the data\n",
    "    Returns:\n",
    "    --------\n",
    "    df_model : pandas.core.frame.DataFrame\n",
    "            The evalution results\n",
    "    \"\"\"\n",
    "    fbeta, precision, recall = {}, {}, {}\n",
    "    for key in trained_models.keys():\n",
    "\n",
    "        predictions = trained_models[key].predict(X_data)\n",
    "\n",
    "        fbeta[key] = fbeta_score(y_data, predictions, beta=1, zero_division=1)\n",
    "        precision[key] = precision_score(predictions, y_data)\n",
    "        recall[key] = recall_score(predictions, y_data)\n",
    "\n",
    "    df_model = pd.DataFrame(index=models.keys(), columns=['fbeta', 'precision', 'recall'])\n",
    "    df_model['fbeta'] = fbeta.values()\n",
    "    df_model['precision'] = precision.values()\n",
    "    df_model['recall'] = recall.values()\n",
    "\n",
    "    return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d458a006-29db-4af4-90e4-75c039d06ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fbeta</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.384543</td>\n",
       "      <td>0.262508</td>\n",
       "      <td>0.718613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extrat Classfier</th>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.172904</td>\n",
       "      <td>0.095574</td>\n",
       "      <td>0.905775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.980250</td>\n",
       "      <td>0.974984</td>\n",
       "      <td>0.985573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Classifier</th>\n",
       "      <td>0.757015</td>\n",
       "      <td>0.698685</td>\n",
       "      <td>0.825972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.418610</td>\n",
       "      <td>0.306607</td>\n",
       "      <td>0.659538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.564904</td>\n",
       "      <td>0.452213</td>\n",
       "      <td>0.752401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fbeta  precision    recall\n",
       "Logistic Regression      0.384543   0.262508  0.718613\n",
       "Extrat Classfier         0.999920   0.999840  1.000000\n",
       "Support Vector Machines  0.172904   0.095574  0.905775\n",
       "Gradient Boosting        0.980250   0.974984  0.985573\n",
       "Decision Trees           0.999920   0.999840  1.000000\n",
       "Random Forest            0.999840   0.999679  1.000000\n",
       "XGB Classifier           0.757015   0.698685  0.825972\n",
       "Naive Bayes              0.418610   0.306607  0.659538\n",
       "K-Nearest Neighbor       0.564904   0.452213  0.752401"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the result of the model for the train data into a dataframe\n",
    "df_train_results = df_model_results(trained_models, X_train, y_train)\n",
    "df_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6f5b0-c2a9-4283-8392-1101d8b3663c",
   "metadata": {},
   "source": [
    "Extrat Classfier, Decision Trees and Random Forest have the best result on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9535663c-4b95-4f07-8c15-598b455f1f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the test processed data\n",
    "X_test, y_test, encoder, lb = process_data(\n",
    "                        test, categorical_features=categorical_features, \n",
    "                        label=\"salary\", training=False, encoder=encoder, lb=binarizer\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d27035-c250-4f63-9d4a-d40af39b5d16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fbeta</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.404826</td>\n",
       "      <td>0.282595</td>\n",
       "      <td>0.713386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extrat Classfier</th>\n",
       "      <td>0.644928</td>\n",
       "      <td>0.610730</td>\n",
       "      <td>0.683182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.257787</td>\n",
       "      <td>0.149719</td>\n",
       "      <td>0.926641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.682452</td>\n",
       "      <td>0.656269</td>\n",
       "      <td>0.710811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.625078</td>\n",
       "      <td>0.617375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.682647</td>\n",
       "      <td>0.630692</td>\n",
       "      <td>0.743929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Classifier</th>\n",
       "      <td>0.720922</td>\n",
       "      <td>0.663132</td>\n",
       "      <td>0.789747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.436333</td>\n",
       "      <td>0.328135</td>\n",
       "      <td>0.650990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.418696</td>\n",
       "      <td>0.332502</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fbeta  precision    recall\n",
       "Logistic Regression      0.404826   0.282595  0.713386\n",
       "Extrat Classfier         0.644928   0.610730  0.683182\n",
       "Support Vector Machines  0.257787   0.149719  0.926641\n",
       "Gradient Boosting        0.682452   0.656269  0.710811\n",
       "Decision Trees           0.621203   0.625078  0.617375\n",
       "Random Forest            0.682647   0.630692  0.743929\n",
       "XGB Classifier           0.720922   0.663132  0.789747\n",
       "Naive Bayes              0.436333   0.328135  0.650990\n",
       "K-Nearest Neighbor       0.418696   0.332502  0.565217"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the result metrics for the test data into a dataframe\n",
    "df_test_results = df_model_results(trained_models, X_test, y_test)\n",
    "df_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a00491-2ab5-4260-b121-ce7a6a6687d0",
   "metadata": {},
   "source": [
    "On the test set the XGB classifier has the best result. We will use Baysian Optimisation to get the best hyperparameter to improve the result for XGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf46fe-2127-4569-a060-46ab4b80c31f",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d90b1755-7e0a-4a2c-832a-d8b31e6dee3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b0797dd-45a7-4c97-9083-d1f7b0d7b880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bo_tune_xgb(max_depth, gamma, eta):\n",
    "    \"\"\"\n",
    "    Function with the internals we wish to maximize\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    max_depth : tuple\n",
    "            Range of maximum depth of a tree.\n",
    "    gamma : tuple\n",
    "        Range of minimum loss reduction required to make a further \n",
    "        partition on a leaf node of the tree.\n",
    "    eta : tuple\n",
    "        Range of step size shrinkage used in update to prevents overfitting. \n",
    "                \n",
    "    \"\"\"\n",
    "    # Define the value range for the parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': int(max_depth),\n",
    "        'eta': eta,\n",
    "        'eval_metric': 'aucpr'\n",
    "    }\n",
    "    \n",
    "    #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
    "    cv_result = xgb.cv(params, training_xgb_matrix, num_boost_round=70, nfold=5)\n",
    "    #Return the resul\n",
    "    cv_result = cv_result['train-aucpr-mean'].iloc[-1]\n",
    "    return 1.0 * cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d809977-77bd-4170-b34d-491001c1a92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate a BayesianOptimization\n",
    "xgb_bo = BayesianOptimization(\n",
    "    bo_tune_xgb, {\n",
    "        'max_depth': (3, 7),\n",
    "        'gamma': (0, 1),\n",
    "        'eta': (0.01, 0.4),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7571b373-3435-4853-ae6f-3d4870975b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group the train data into a xgb.DMatrix\n",
    "training_xgb_matrix = xgb.DMatrix(X_train, label=y_train)\n",
    "test_xgb_matrix = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74980200-16ed-401e-b7cd-676e28118086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    eta    |   gamma   | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7819   \u001b[0m | \u001b[0m0.02299  \u001b[0m | \u001b[0m0.6109   \u001b[0m | \u001b[0m4.923    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.8439   \u001b[0m | \u001b[95m0.07822  \u001b[0m | \u001b[95m0.5166   \u001b[0m | \u001b[95m6.171    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.8817   \u001b[0m | \u001b[95m0.3877   \u001b[0m | \u001b[95m0.09242  \u001b[0m | \u001b[95m5.37     \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8462   \u001b[0m | \u001b[0m0.2047   \u001b[0m | \u001b[0m0.9859   \u001b[0m | \u001b[0m4.716    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8108   \u001b[0m | \u001b[0m0.1152   \u001b[0m | \u001b[0m0.613    \u001b[0m | \u001b[0m3.833    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8083   \u001b[0m | \u001b[0m0.1073   \u001b[0m | \u001b[0m0.1758   \u001b[0m | \u001b[0m3.436    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8604   \u001b[0m | \u001b[0m0.3511   \u001b[0m | \u001b[0m0.9116   \u001b[0m | \u001b[0m4.101    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8627   \u001b[0m | \u001b[0m0.3698   \u001b[0m | \u001b[0m0.1637   \u001b[0m | \u001b[0m4.311    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8802   \u001b[0m | \u001b[0m0.2464   \u001b[0m | \u001b[0m0.907    \u001b[0m | \u001b[0m6.745    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.7907   \u001b[0m | \u001b[0m0.03422  \u001b[0m | \u001b[0m0.2617   \u001b[0m | \u001b[0m4.954    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8805   \u001b[0m | \u001b[0m0.3644   \u001b[0m | \u001b[0m0.001607 \u001b[0m | \u001b[0m5.625    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8804   \u001b[0m | \u001b[0m0.3734   \u001b[0m | \u001b[0m0.1046   \u001b[0m | \u001b[0m5.372    \u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m0.9219   \u001b[0m | \u001b[95m0.4      \u001b[0m | \u001b[95m0.4615   \u001b[0m | \u001b[95m7.0      \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9219   \u001b[0m | \u001b[0m0.4      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m7.0      \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the the optimization\n",
    "xgb_bo.maximize(n_iter=6, init_points=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d44f1bf-2736-48be-bd2d-ce5f392106e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.4, 'gamma': 0.4615229241874462, 'max_depth': 7.0}\n"
     ]
    }
   ],
   "source": [
    "# Show the best hypermarameters\n",
    "params = xgb_bo.max['params']\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b0763-17b8-4624-9a3c-90ddc7e9ed5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrain the model with the best hyperparameter\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': round(params['eta'], 1),\n",
    "    'max_depth': round(params['max_depth']),\n",
    "    'gamma': round(params['gamma']),\n",
    "    'eval_metric': 'aucpr',\n",
    "}\n",
    "\n",
    "# Create a list of xgb.DMatrix\n",
    "watch_list = [\n",
    "                (test_xgb_matrix, 'eval'),\n",
    "                (training_xgb_matrix, 'train')\n",
    "            ]\n",
    "\n",
    "# Train the model with the selected hyperparameters\n",
    "xgb_model = xgb.train(params,\n",
    "                          training_xgb_matrix,\n",
    "                          num_boost_round=999,\n",
    "                          evals=watch_list,\n",
    "                          early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1748304b-aa10-4b0b-85a3-cb4269796639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_type(y_pred, y_label):\n",
    "    \"\"\"\n",
    "    Get classification type\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y_pred : numpy.ndarray\n",
    "        The predictions result\n",
    "    y_label : numpy.ndarray\n",
    "        The actual label\n",
    "    Returns:\n",
    "    --------\n",
    "    rs : str\n",
    "        The clasification type\n",
    "    \"\"\"\n",
    "    \n",
    "    rs = 'TP' if y_pred == 1 and y_label == 1 else 'FP' if y_pred == 1 and y_label == 0 else 'TN' if y_pred == 0 and y_label == 0 else 'FN'\n",
    "    return rs\n",
    "\n",
    "def evaluation(threshold):\n",
    "    \"\"\"\n",
    "    Get the evaluation result\n",
    "    Inputs:\n",
    "    -------\n",
    "    threshold: float\n",
    "            The value that we need to compare the prediction result with\n",
    "    Returns:\n",
    "    --------\n",
    "    precision : float\n",
    "            The model precision\n",
    "    recall : float\n",
    "        The recall ratio\n",
    "    fscore : float\n",
    "        The F1 score\n",
    "    accuracy : float\n",
    "        The accuracy of the model\n",
    "    y_test: numpy.ndarray\n",
    "        The test label\n",
    "    y_predict : numpy.ndarray\n",
    "            The predicted label\n",
    "    \"\"\"\n",
    "    test_evaluation = test.copy()\n",
    "    predictions = xgb_model.predict(test_xgb_matrix)\n",
    "    test_evaluation['label'] = test_evaluation.apply(lambda x: 0 if x['salary'] == \"<=50k\" else 1, axis=1)\n",
    "    test_evaluation['predicted_score'] = predictions\n",
    "    test_evaluation['predicted_label'] = test_evaluation.apply(lambda x: 1 if x['predicted_score'] >= threshold else 0, axis = 1)\n",
    "    test_evaluation['type'] = test_evaluation.apply(lambda x: classify_type(x['predicted_label'], x['label']), axis = 1)\n",
    "    y_predict = test_evaluation['predicted_label'].tolist()\n",
    "    precision, recall, fscore, support = score(y_test, y_predict)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "    return round(recall[1], 2), round(precision[1], 2), round(fscore[1], 2), round(accuracy, 2), y_test, y_predict, support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "716c7af9-b3ef-4608-8a0c-0db0fc785319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the evaluation result\n",
    "threshold = 0.5\n",
    "recall, precision, fscore, accuracy, y_test, y_predict, support = evaluation(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "45a76753-b675-4c0a-82c6-28ad79e94702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.66\n",
      "precision: 0.79\n",
      "fscore: 0.72\n",
      "support: [4905 1603]\n",
      "accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation result\n",
    "print('recall: {}'.format(recall))\n",
    "print('precision: {}'.format(precision))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print('accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9cbd3d94-66c0-427a-9aee-b3332b1c1995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      4905\n",
      "           1       0.79      0.66      0.72      1603\n",
      "\n",
      "    accuracy                           0.87      6508\n",
      "   macro avg       0.84      0.80      0.82      6508\n",
      "weighted avg       0.87      0.87      0.87      6508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report result\n",
    "print(classification_report(y_test, test_evaluation['predicted_label'].values, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada76b3-1056-4c32-bdc8-63e71e711c9a",
   "metadata": {},
   "source": [
    "We noticed that the model give better result for the label 0 than the label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "61d1e163-aaf2-4593-a577-1d4c0707aa01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>person_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary  person_count\n",
       "0  <=50K          4905\n",
       "1   >50K          1603"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the distribution of the salary\n",
    "test.groupby(['salary']).agg(person_count=(\"salary\", \"count\")).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e53fa-a0f3-4f61-8631-6cb0b27f26bc",
   "metadata": {},
   "source": [
    "This model can be improve if we do explainable AI to find what is wrong with the data, maybe find the bias and analyse the False Positive and the False negative to know why we get thos results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9bc89-5b02-4b4d-81e2-6b583e894c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
